# Jour 4 â€” Optimisations GPU + ItÃ©ration I3 (et I4 si besoin)

## ğŸ¯ Objectif
RÃ©duire la latence sans dÃ©grader la prÃ©cision en dessous de 85%.

---

## ğŸ“‹ TÃ¢ches

### âš¡ I3.1 â€” InfÃ©rence FP16 (autocast)

- [X] **J4-01** | ImplÃ©menter l'infÃ©rence en FP16
  - **Description** :
    ```python
    with torch.cuda.amp.autocast(dtype=torch.float16):
        output = model(input)
    ```
  - **Labels** : `optimisation`, `FP16`
  - **PrioritÃ©** : ğŸ”´ Haute

- [X] **J4-02** | Mesurer la latence FP16 (modÃ¨le lÃ©ger)
  - **Description** :
    - Appliquer sur MobileNetV3/ShuffleNet (B1)
    - Benchmark : warm-up + mesure (moyenne + p95)
    - Comparer avec baseline FP32
  - **Labels** : `benchmark`, `latence`
  - **PrioritÃ©** : ğŸ”´ Haute

- [X] **J4-03** | VÃ©rifier l'accuracy en FP16
  - **Description** : S'assurer que l'accuracy ne chute pas significativement (< 0.5%)
  - **Labels** : `validation`, `accuracy`
  - **PrioritÃ©** : ğŸ”´ Haute

- [X] **J4-04** | Mesurer la latence FP16 (ResNet-18)
  - **Description** : Appliquer le mÃªme test sur le teacher pour comparaison
  - **Labels** : `benchmark`, `latence`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

### ğŸ”§ I3.2 â€” torch.compile (si stable)

- [X] **J4-05** | Tester torch.compile sur le modÃ¨le lÃ©ger
  - **Description** :
    ```python
    model_compiled = torch.compile(model, mode="reduce-overhead")
    ```
    - Mode recommandÃ© pour batch=1 : `"reduce-overhead"` ou `"max-autotune"`
  - **Labels** : `optimisation`, `compile`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [X] **J4-06** | Mesurer le temps de compilation
  - **Description** :
    - Noter le temps de premiÃ¨re exÃ©cution (compilation)
    - Ce temps est **hors mÃ©trique** de latence
  - **Labels** : `benchmark`, `documentation`
  - **PrioritÃ©** : ğŸŸ¢ Basse

- [X] **J4-07** | Mesurer la latence post-compilation
  - **Description** :
    - Benchmark aprÃ¨s compilation complÃ¨te
    - Comparer avec FP32 et FP16 sans compile
  - **Labels** : `benchmark`, `latence`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [X] **J4-08** | Combiner FP16 + torch.compile
  - **Description** :
    - Tester la combinaison des deux optimisations
    - Mesurer latence (moyenne + p95)
  - **Labels** : `optimisation`, `benchmark`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [X] **J4-09** | GÃ©rer l'instabilitÃ© torch.compile
  - **Description** :
    - Si erreurs ou crashes : documenter et passer en fallback
    - Fallback : FP16 seul ou TorchScript (optionnel)
    - Statut : compilations FP32/FP16 stables sous WSL (chemin sans espaces) ; fallback FP16 seul prÃªt si rÃ©gression ultÃ©rieure
  - **Labels** : `risque`, `fallback`
  - **PrioritÃ©** : ğŸŸ¢ Basse

---

### ğŸ”„ I3.3 â€” Format channels_last

- [X] **J4-10** | Convertir le modÃ¨le en channels_last
  - **Description** :
    ```python
    model = model.to(memory_format=torch.channels_last)
    input = input.to(memory_format=torch.channels_last)
    ```
  - **Labels** : `optimisation`, `mÃ©moire`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [X] **J4-11** | Mesurer la latence channels_last (modÃ¨le lÃ©ger)
  - **Description** :
    - Tester sur MobileNetV3/ShuffleNet
    - Comparer avec baseline FP32
  - **Labels** : `benchmark`, `latence`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne
  - **RÃ©sultat** : MobileNetV3 FP32 et FP16 testÃ©s (warmup 10, runs 50) â†’ aucun gain, lÃ©gÃ¨re rÃ©gression en FP32, gain p95 marginal en FP16. Channels_last non retenu.

- [X] **J4-12** | Mesurer la latence channels_last (ResNet-18)
  - **Description** : Tester sur le teacher pour comparaison
  - **Labels** : `benchmark`, `latence`
  - **PrioritÃ©** : ğŸŸ¢ Basse
  - **RÃ©sultat** : non poursuivi aprÃ¨s constat d'absence de gain sur MobileNetV3; channels_last abandonnÃ©.

- [X] **J4-13** | DÃ©cider de garder channels_last
  - **Description** :
    - Garder uniquement si amÃ©lioration mesurable (>5%)
    - Sinon abandonner cette piste
  - **Labels** : `dÃ©cision`, `analyse`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne
  - **DÃ©cision** : abandonner channels_last (gain < 5%, voire rÃ©gression).

---

### ğŸ“ I4 â€” Distillation (optionnelle)

> âš ï¸ **Condition** : ExÃ©cuter cette section uniquement si le modÃ¨le lÃ©ger < 85% accuracy

- [X] **J4-14** | ImplÃ©menter la perte de distillation
  - **Description** :
    ```python
    # Loss = Î± * KL(soft_student, soft_teacher) + (1-Î±) * CE(student, labels)
    # Temperature T = 4-6 typiquement
    loss_kl = F.kl_div(
        F.log_softmax(student_logits / T, dim=1),
        F.softmax(teacher_logits / T, dim=1),
        reduction='batchmean'
    ) * (T * T)
    loss_ce = F.cross_entropy(student_logits, labels)
    loss = alpha * loss_kl + (1 - alpha) * loss_ce
    ```
  - **Labels** : `distillation`, `code`
  - **PrioritÃ©** : ğŸ”´ Haute (si nÃ©cessaire)
  - **Statut** : ImplÃ©mentÃ© via util `distillation_loss` (combina KL + CE) dans src/cifaracce/utils/distillation.py (alpha=0.7, T=4 par dÃ©faut), prÃªt pour l'entraÃ®nement.

- [X] **J4-15** | Configurer l'entraÃ®nement distillation
  - **Description** :
    - Teacher : ResNet-18 (J3) en mode eval, frozen
    - Student : MobileNetV3/ShuffleNet (J2)
    - HyperparamÃ¨tres : T=4, Î±=0.7, LR=0.01
  - **Labels** : `distillation`, `configuration`
  - **PrioritÃ©** : ğŸ”´ Haute (si nÃ©cessaire)
  - **Statut** : Script de distillation prÃªt (scripts/distillation/train_distill_mobilenet_j4.py) : teacher ResNet-18 gelÃ©, student MobileNetV3, T=4, Î±=0.7, LR=0.01.

- [X] **J4-16** | EntraÃ®ner le student avec distillation
  - **Description** :
    - Epochs : 100-200
    - Objectif : Student â‰¥85% accuracy
  - **Labels** : `distillation`, `entraÃ®nement`
  - **PrioritÃ©** : ğŸ”´ Haute (si nÃ©cessaire)

- [X] **J4-17** | Ã‰valuer le student distillÃ©
  - **Description** :
    - Accuracy sur test
    - Latence GPU (FP16)
  - **Labels** : `Ã©valuation`, `mÃ©triques`
  - **PrioritÃ©** : ğŸ”´ Haute (si nÃ©cessaire)

---

### ğŸ“Š SynthÃ¨se et dÃ©cision

- [X] **J4-18** | Mettre Ã  jour le tableau comparatif
  - **Description** : Ajouter toutes les variantes testÃ©es
    | ID | Variante | Acc. (%) | Lat. moy. (ms) | Lat. p95 (ms) | Taille (MB) |
    |----|----------|----------|----------------|---------------|-------------|
    | O1 | B1 + FP16 | ... | ... | ... | ... |
    | O2 | B1 + FP16 + compile | ... | ... | ... | ... |
    | O3 | B1 + channels_last | ... | ... | ... | ... |
    | D1 | Distillation student (FP16) | ... | ... | ... | ... |
  - **Labels** : `documentation`, `rÃ©sultats`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J4-19** | Analyser les rÃ©sultats
  - **Description** :
    - Identifier le gain de chaque optimisation
    - Calculer le speedup vs baseline FP32
    - VÃ©rifier contrainte accuracy â‰¥85%
  - **Labels** : `analyse`, `dÃ©cision`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J4-20** | SÃ©lectionner le candidat final
  - **Description** :
    - Choisir le meilleur compromis accuracy/latence
    - Documenter la justification du choix
  - **Labels** : `dÃ©cision`, `documentation`
  - **PrioritÃ©** : ğŸ”´ Haute

---

## âœ… CritÃ¨res d'acceptation J4

- [X] FP16 testÃ© et mesurÃ© sur les deux modÃ¨les
- [X] torch.compile testÃ© (ou documentÃ© si instable)
- [X] channels_last testÃ© (dÃ©cision prise)
- [X] Distillation rÃ©alisÃ©e si nÃ©cessaire
- [X] Tableau comparatif complet (toutes variantes)
- [ ] **Candidat final sÃ©lectionnÃ©** (meilleur compromis)

---

## ğŸ“ˆ Sorties attendues

| Livrable | Statut |
|----------|--------|
| Benchmark FP16 complÃ©tÃ© | â¬œ |
| Benchmark torch.compile complÃ©tÃ© | â¬œ |
| Benchmark channels_last complÃ©tÃ© | â¬œ |
| Distillation (si nÃ©cessaire) | â¬œ |
| Tableau comparatif mis Ã  jour | â¬œ |
| Candidat final identifiÃ© | â¬œ |

---

## ğŸš¨ Points d'attention

- **torch.compile** peut Ãªtre instable : prÃ©voir un fallback
- **FP16** : vÃ©rifier que l'accuracy ne chute pas
- **channels_last** : peut ne pas apporter de gain sur tous les modÃ¨les
- **Distillation** : seulement si modÃ¨le lÃ©ger < 85%

---

## ğŸ“Š Matrice de dÃ©cision

| Optimisation | Gain latence attendu | Risque | PrioritÃ© |
|--------------|---------------------|--------|----------|
| FP16 | 20-50% | Faible | ğŸ”´ Haute |
| torch.compile | 10-30% | Moyen | ğŸŸ¡ Moyenne |
| channels_last | 5-15% | Faible | ğŸŸ¡ Moyenne |
| Distillation | N/A (accuracy) | Moyen | Conditionnelle |

---

## ğŸ”€ Arbre de dÃ©cision J4

```
ModÃ¨le lÃ©ger (J2) accuracy ?
â”œâ”€â”€ â‰¥85% â†’ Optimisations I3 seulement
â”‚   â””â”€â”€ FP16 â†’ compile â†’ channels_last
â””â”€â”€ <85% â†’ Distillation I4 nÃ©cessaire
    â””â”€â”€ Teacher (J3) â†’ Student â†’ puis I3
```

