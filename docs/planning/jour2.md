# Jour 2 â€” Baseline vitesse + ItÃ©ration I1

## ğŸ¯ Objectif
EntraÃ®ner un modÃ¨le lÃ©ger from-scratch et mesurer sa latence.

---

## ğŸ“‹ TÃ¢ches

### ğŸ”§ Configuration du modÃ¨le lÃ©ger

- [X] **J2-01** | Choisir l'architecture lÃ©gÃ¨re
  - **Description** : SÃ©lectionner entre MobileNetV3-Small et ShuffleNetV2 pour le baseline vitesse
  - **Labels** : `architecture`, `dÃ©cision`
  - **PrioritÃ©** : ğŸ”´ Haute

- [X] **J2-02** | Adapter le modÃ¨le pour CIFAR-10
  - **Description** : 
    - Instancier avec `weights=None` (pas de poids ImageNet)
    - Modifier la tÃªte de sortie pour **10 classes**
    - Adapter la premiÃ¨re couche conv si nÃ©cessaire (images 32Ã—32)
  - **Labels** : `code`, `modÃ¨le`
  - **PrioritÃ©** : ğŸ”´ Haute

- [X] **J2-03** | Configurer la gestion du device
  - **Description** : Assurer le transfert propre du modÃ¨le et des donnÃ©es sur GPU
  - **Labels** : `code`, `GPU`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

### ğŸ‹ï¸ EntraÃ®nement

- [X] **J2-04** | DÃ©finir les hyperparamÃ¨tres d'entraÃ®nement
  - **Description** :
    - Learning rate initial
    - Scheduler (CosineAnnealing, StepLR, etc.)
    - Optimizer (SGD+momentum ou AdamW)
    - Nombre d'epochs (objectif : â‰¥80% rapidement)
    - Batch size
  - **Labels** : `hyperparamÃ¨tres`, `configuration`
  - **PrioritÃ©** : ğŸ”´ Haute

- [X] **J2-05** | Configurer les augmentations de donnÃ©es
  - **Description** :
    - RandomCrop avec padding
    - RandomHorizontalFlip
    - Normalisation CIFAR-10
    - (Optionnel) Cutout, AutoAugment. They can help, not yet impelmented
  - **Labels** : `data`, `augmentation`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [X] **J2-06** | Lancer l'entraÃ®nement du modÃ¨le lÃ©ger
  - **Description** : EntraÃ®ner MobileNetV3-Small sur CIFAR-10 train
  - **CritÃ¨re de succÃ¨s** : Atteindre â‰¥80%, viser â‰¥85%
  - **Labels** : `entraÃ®nement`, `exÃ©cution`
  - **PrioritÃ©** : ğŸ”´ Haute

- [X] **J2-07** | Sauvegarder les checkpoints
  - **Description** :
    - Sauvegarder le meilleur modÃ¨le (best accuracy)
    - Sauvegarder le dernier modÃ¨le
    - Logger les mÃ©triques (loss train/test, accuracy train/test)
  - **Labels** : `sauvegarde`, `logs`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

### ğŸ“Š Ã‰valuation et mesures

- [ ] **J2-08** | Ã‰valuer l'accuracy sur le jeu de test
  - **Description** : Calculer l'accuracy finale sur CIFAR-10 test
  - **CritÃ¨re de succÃ¨s** : Documenter le rÃ©sultat mÃªme si < 85%
  - **Labels** : `Ã©valuation`, `mÃ©triques`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J2-09** | Mesurer la latence GPU (FP32)
  - **Description** :
    - Utiliser le benchmark dÃ©veloppÃ© en J1
    - Batch = 1, entrÃ©e sur GPU
    - Warm-up + mesure (moyenne + p95)
  - **Labels** : `benchmark`, `latence`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J2-10** | Documenter la taille du modÃ¨le
  - **Description** :
    - Nombre de paramÃ¨tres
    - Taille du fichier checkpoint (MB)
  - **Labels** : `mÃ©triques`, `documentation`
  - **PrioritÃ©** : ğŸŸ¢ Basse

---

### ğŸ“ Documentation et suivi

- [ ] **J2-11** | Remplir la premiÃ¨re ligne du tableau comparatif
  - **Description** : Ajouter les rÃ©sultats dans le tableau (B1 : MobileNetV3/ShuffleNet FP32)
    | ID | Variante | Acc. (%) | Lat. moy. (ms) | Lat. p95 (ms) | Taille (MB) |
    |----|----------|----------|----------------|---------------|-------------|
    | B1 | ... | ... | ... | ... | ... |
  - **Labels** : `documentation`, `rÃ©sultats`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J2-12** | Logger les hyperparamÃ¨tres utilisÃ©s
  - **Description** : Documenter tous les choix pour reproductibilitÃ©
  - **Labels** : `documentation`, `reproductibilitÃ©`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

## âœ… CritÃ¨res d'acceptation J2

- [ ] Au moins un modÃ¨le lÃ©ger entraÃ®nÃ© from-scratch
- [ ] RÃ©sultats mesurÃ©s : accuracy + latence moyenne + latence p95
- [ ] PremiÃ¨re ligne du tableau comparatif remplie
- [ ] Checkpoints et logs sauvegardÃ©s

---

## ğŸ“ˆ Sorties attendues

| Livrable | Statut |
|----------|--------|
| ModÃ¨le lÃ©ger entraÃ®nÃ© | â¬œ |
| Accuracy sur test documentÃ©e | â¬œ |
| Latence GPU (FP32) mesurÃ©e | â¬œ |
| Tableau comparatif (1Ã¨re ligne) | â¬œ |

---

## ğŸš¨ Points d'attention

- Si accuracy < 80% : ajuster LR, augmentations, ou nombre d'epochs
- Si accuracy entre 80-85% : noter pour potentielle distillation J4
- Bien utiliser `model.eval()` et `torch.no_grad()` pour les mesures

