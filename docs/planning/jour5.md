# Jour 5 â€” Consolidation + ItÃ©ration I5

## ğŸ¯ Objectif
Finaliser les livrables, assurer la reproductibilitÃ© et rÃ©diger la narration de la dÃ©marche.

---

## ğŸ“‹ TÃ¢ches

### ğŸ§¹ Nettoyage et organisation du code

- [ ] **J5-01** | Structurer les scripts Python
  - **Description** :
    - `train.py` â€” EntraÃ®nement des modÃ¨les
    - `eval.py` â€” Ã‰valuation accuracy sur test
    - `bench.py` â€” Benchmark latence GPU
    - `distill.py` â€” Distillation (si utilisÃ©e)
  - **Labels** : `code`, `organisation`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-02** | Nettoyer les notebooks
  - **Description** :
    - Supprimer les cellules de debug/test
    - Ajouter des commentaires explicatifs
    - Structurer en sections claires
    - VÃ©rifier que les notebooks s'exÃ©cutent de bout en bout
  - **Labels** : `code`, `documentation`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J5-03** | CrÃ©er un fichier de configuration
  - **Description** :
    - `config.py` ou `config.yaml` avec tous les hyperparamÃ¨tres
    - Chemins des checkpoints
    - ParamÃ¨tres du benchmark
  - **Labels** : `configuration`, `reproductibilitÃ©`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

### ğŸ”’ ReproductibilitÃ©

- [ ] **J5-04** | Figer les seeds
  - **Description** :
    ```python
    import torch
    import numpy as np
    import random
    
    def set_seed(seed=42):
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        np.random.seed(seed)
        random.seed(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    ```
  - **Labels** : `reproductibilitÃ©`, `code`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-05** | Logger les versions des dÃ©pendances
  - **Description** :
    - PyTorch version
    - torchvision version
    - CUDA version
    - Python version
    - GPU utilisÃ© (nom, driver)
    - CrÃ©er `requirements.txt` ou `environment.yml`
  - **Labels** : `reproductibilitÃ©`, `documentation`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-06** | Documenter les chemins des checkpoints
  - **Description** :
    - Liste tous les checkpoints sauvegardÃ©s
    - PrÃ©ciser lequel est le modÃ¨le final
    - Format : `checkpoints/model_name_epoch_accuracy.pth`
  - **Labels** : `documentation`, `organisation`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

### ğŸ“ Mesures finales

- [ ] **J5-07** | Effectuer 3 runs de benchmark pour le candidat final
  - **Description** :
    - ExÃ©cuter le benchmark 3 fois
    - Calculer moyenne et Ã©cart-type des latences
    - VÃ©rifier la stabilitÃ© des mesures
  - **Labels** : `benchmark`, `validation`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-08** | Effectuer 3 runs de benchmark pour le baseline
  - **Description** :
    - MÃªme protocole sur B1 (modÃ¨le lÃ©ger FP32)
    - Permet de calculer le speedup final
  - **Labels** : `benchmark`, `validation`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J5-09** | VÃ©rifier l'accuracy finale
  - **Description** :
    - Recharger le checkpoint final
    - Ã‰valuer sur CIFAR-10 test
    - Confirmer â‰¥85%
  - **Labels** : `validation`, `accuracy`
  - **PrioritÃ©** : ğŸ”´ Haute

---

### ğŸ“Š Tableau final et analyse

- [ ] **J5-10** | ComplÃ©ter le tableau de rÃ©sultats final
  - **Description** :
    | ID | Variante | Acc. (%) | Lat. moy. (ms) | Lat. p95 (ms) | Taille (MB) | Speedup |
    |----|----------|----------|----------------|---------------|-------------|---------|
    | B1 | MobileNetV3/ShuffleNet (FP32) | ... | ... | ... | ... | 1.0Ã— |
    | B2 | ResNet-18 CIFAR (FP32) | ... | ... | ... | ... | ... |
    | O1 | B1 + FP16 | ... | ... | ... | ... | ... |
    | O2 | B1 + FP16 + compile | ... | ... | ... | ... | ... |
    | O3 | B1 + channels_last | ... | ... | ... | ... | ... |
    | D1 | Distillation student (FP16) | ... | ... | ... | ... | ... |
    | **F** | **Candidat final** | ... | ... | ... | ... | ... |
  - **Labels** : `documentation`, `rÃ©sultats`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-11** | Calculer les speedups
  - **Description** :
    - Speedup = Latence_baseline / Latence_variante
    - RÃ©fÃ©rence : B1 FP32 (baseline vitesse)
  - **Labels** : `analyse`, `mÃ©triques`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J5-12** | RÃ©diger l'analyse des rÃ©sultats
  - **Description** :
    - Ce qui a Ã©tÃ© tentÃ©
    - Ce qui a marchÃ© / pas marchÃ©
    - Justification du choix final
    - Limites et perspectives
  - **Labels** : `documentation`, `analyse`
  - **PrioritÃ©** : ğŸ”´ Haute

---

### ğŸ“ Rapport final

- [ ] **J5-13** | RÃ©diger l'introduction du rapport
  - **Description** :
    - Contexte du projet
    - Objectifs (accuracy â‰¥85%, latence minimale)
    - Contraintes (CIFAR-10 only, GPU batch=1)
  - **Labels** : `rapport`, `rÃ©daction`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J5-14** | DÃ©crire la mÃ©thodologie
  - **Description** :
    - DÃ©marche incrÃ©mentale : baseline â†’ optimisation â†’ mesure
    - Protocole de benchmark (warm-up, sync, stats)
    - Architectures testÃ©es
  - **Labels** : `rapport`, `rÃ©daction`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-15** | PrÃ©senter les rÃ©sultats
  - **Description** :
    - Tableau comparatif
    - Graphiques (optionnel) : barplot latence, scatter accuracy vs latence
    - Analyse des gains
  - **Labels** : `rapport`, `visualisation`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-16** | RÃ©diger la conclusion
  - **Description** :
    - RÃ©sumÃ© des rÃ©sultats
    - ModÃ¨le final retenu et pourquoi
    - AmÃ©liorations possibles
  - **Labels** : `rapport`, `rÃ©daction`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

### ğŸ“¦ Livrables

- [ ] **J5-17** | PrÃ©parer le package de livraison
  - **Description** :
    ```
    projet/
    â”œâ”€â”€ README.md           # Instructions d'utilisation
    â”œâ”€â”€ requirements.txt    # DÃ©pendances
    â”œâ”€â”€ config.py           # Configuration
    â”œâ”€â”€ train.py            # EntraÃ®nement
    â”œâ”€â”€ eval.py             # Ã‰valuation
    â”œâ”€â”€ bench.py            # Benchmark
    â”œâ”€â”€ checkpoints/
    â”‚   â””â”€â”€ final_model.pth # ModÃ¨le final
    â”œâ”€â”€ results/
    â”‚   â””â”€â”€ results.csv     # RÃ©sultats benchmark
    â””â”€â”€ rapport.pdf         # Rapport final
    ```
  - **Labels** : `livrable`, `organisation`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-18** | RÃ©diger le README
  - **Description** :
    - Installation des dÃ©pendances
    - Comment entraÃ®ner un modÃ¨le
    - Comment Ã©valuer l'accuracy
    - Comment lancer le benchmark
    - Comment reproduire les rÃ©sultats
  - **Labels** : `documentation`, `livrable`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J5-19** | Exporter le modÃ¨le final
  - **Description** :
    - Sauvegarder `state_dict` propre
    - (Optionnel) Export TorchScript pour dÃ©ploiement
    - Documenter le format et le chargement
  - **Labels** : `livrable`, `modÃ¨le`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J5-20** | VÃ©rification finale
  - **Description** :
    - Tester le chargement du modÃ¨le final
    - VÃ©rifier que le benchmark fonctionne
    - Relire le rapport
    - S'assurer que tout est reproductible
  - **Labels** : `validation`, `qualitÃ©`
  - **PrioritÃ©** : ğŸ”´ Haute

---

## âœ… CritÃ¨res d'acceptation J5

- [ ] Code nettoyÃ© et organisÃ© (scripts ou notebooks)
- [ ] ReproductibilitÃ© assurÃ©e (seeds, versions, configs)
- [ ] 3 runs de mesure finale effectuÃ©s
- [ ] Tableau de rÃ©sultats complet avec speedups
- [ ] Analyse Ã©crite (ce qui a marchÃ©/pas marchÃ©)
- [ ] Rapport finalisÃ©
- [ ] **ModÃ¨le final â‰¥85% accuracy + meilleure latence**
- [ ] Package de livraison prÃªt

---

## ğŸ“ˆ Sorties attendues

| Livrable | Statut |
|----------|--------|
| Code nettoyÃ© | â¬œ |
| requirements.txt | â¬œ |
| Mesures finales (3 runs) | â¬œ |
| Tableau comparatif final | â¬œ |
| Analyse des rÃ©sultats | â¬œ |
| Rapport complet | â¬œ |
| README.md | â¬œ |
| ModÃ¨le final (.pth) | â¬œ |
| results.csv | â¬œ |

---

## ğŸš¨ Points d'attention

- **Deadline** : tout doit Ãªtre finalisÃ© aujourd'hui
- Ne pas oublier de **vÃ©rifier l'accuracy** aprÃ¨s rechargement du modÃ¨le
- Les **3 runs** de benchmark sont essentiels pour la crÃ©dibilitÃ©
- Le **README** doit permettre Ã  quelqu'un d'autre de reproduire les rÃ©sultats

---

## ğŸ“‹ Checklist de livraison

```
[ ] Le modÃ¨le final atteint â‰¥85% accuracy
[ ] La latence est la meilleure parmi les variantes
[ ] Le code s'exÃ©cute sans erreur
[ ] Les rÃ©sultats sont reproductibles
[ ] Le rapport est complet et clair
[ ] Le README explique comment utiliser le projet
[ ] Tous les fichiers sont prÃ©sents dans le package
```

