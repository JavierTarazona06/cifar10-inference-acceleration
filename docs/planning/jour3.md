# Jour 3 â€” Baseline prÃ©cision (teacher) + ItÃ©ration I2

## ğŸ¯ Objectif
Obtenir une rÃ©fÃ©rence robuste â‰¥85% et disposer d'un teacher pour la distillation.

---

## ğŸ“‹ TÃ¢ches

### ğŸ—ï¸ Architecture ResNet-18 adaptÃ©e CIFAR

- [ ] **J3-01** | ImplÃ©menter ResNet-18 adaptÃ©e CIFAR-10
  - **Description** :
    - Modifier la premiÃ¨re couche conv : kernel 3Ã—3, stride 1, padding 1 (au lieu de 7Ã—7)
    - Supprimer le MaxPool initial (images 32Ã—32 trop petites)
    - TÃªte de sortie Ã  **10 classes**
    - `weights=None` (entraÃ®nement from-scratch)
  - **Labels** : `architecture`, `code`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J3-02** | VÃ©rifier le forward pass
  - **Description** : Tester avec un batch fictif (1, 3, 32, 32) et vÃ©rifier la sortie (1, 10)
  - **Labels** : `test`, `validation`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

### âš™ï¸ Configuration de l'entraÃ®nement

- [ ] **J3-03** | DÃ©finir les hyperparamÃ¨tres
  - **Description** :
    - **LR initial** : 0.1 (typique pour SGD sur CIFAR)
    - **Optimizer** : SGD avec momentum 0.9, weight decay 5e-4
    - **Scheduler** : CosineAnnealingLR ou MultiStepLR (milestones 100, 150)
    - **Epochs** : 200 (ou moins si convergence rapide)
    - **Batch size** : 128
  - **Labels** : `hyperparamÃ¨tres`, `configuration`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J3-04** | Configurer les augmentations robustes
  - **Description** :
    - RandomCrop(32, padding=4)
    - RandomHorizontalFlip(p=0.5)
    - Normalisation CIFAR-10 : mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)
    - (Optionnel) Cutout, MixUp, ou AutoAugment si besoin de boost
  - **Labels** : `data`, `augmentation`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J3-05** | Ajouter rÃ©gularisation si nÃ©cessaire
  - **Description** :
    - Weight decay (dÃ©jÃ  dans optimizer)
    - Label smoothing (optionnel)
    - Dropout (optionnel, peu utilisÃ© dans ResNet)
  - **Labels** : `rÃ©gularisation`, `configuration`
  - **PrioritÃ©** : ğŸŸ¢ Basse

---

### ğŸ‹ï¸ EntraÃ®nement du teacher

- [ ] **J3-06** | Lancer l'entraÃ®nement ResNet-18
  - **Description** : EntraÃ®ner le modÃ¨le sur CIFAR-10 train
  - **CritÃ¨re de succÃ¨s** : Atteindre **â‰¥85% accuracy** sur test
  - **Labels** : `entraÃ®nement`, `exÃ©cution`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J3-07** | Monitorer l'entraÃ®nement
  - **Description** :
    - Logger loss train/val Ã  chaque epoch
    - Logger accuracy train/val
    - DÃ©tecter overfitting (gap train/val)
  - **Labels** : `monitoring`, `logs`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J3-08** | Sauvegarder les checkpoints
  - **Description** :
    - `resnet18_cifar_best.pth` (meilleure accuracy val)
    - `resnet18_cifar_last.pth` (dernier epoch)
    - Sauvegarder aussi l'optimizer state (pour reprise)
  - **Labels** : `sauvegarde`, `checkpoints`
  - **PrioritÃ©** : ğŸ”´ Haute

---

### ğŸ“Š Ã‰valuation et mesures

- [ ] **J3-09** | Ã‰valuer l'accuracy finale sur test
  - **Description** : Charger le best checkpoint et calculer l'accuracy sur CIFAR-10 test
  - **CritÃ¨re de succÃ¨s** : **â‰¥85%**
  - **Labels** : `Ã©valuation`, `mÃ©triques`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J3-10** | Mesurer la latence GPU (FP32)
  - **Description** :
    - Utiliser le benchmark J1
    - Batch = 1, entrÃ©e sur GPU
    - Warm-up + mesure (moyenne + p95)
  - **Labels** : `benchmark`, `latence`
  - **PrioritÃ©** : ğŸ”´ Haute

- [ ] **J3-11** | Documenter la taille du modÃ¨le
  - **Description** :
    - Nombre de paramÃ¨tres (~11M pour ResNet-18)
    - Taille du fichier checkpoint (MB)
  - **Labels** : `mÃ©triques`, `documentation`
  - **PrioritÃ©** : ğŸŸ¢ Basse

---

### ğŸ“ Documentation et suivi

- [ ] **J3-12** | Mettre Ã  jour le tableau comparatif
  - **Description** : Ajouter les rÃ©sultats dans le tableau (B2 : ResNet-18 CIFAR FP32)
    | ID | Variante | Acc. (%) | Lat. moy. (ms) | Lat. p95 (ms) | Taille (MB) |
    |----|----------|----------|----------------|---------------|-------------|
    | B2 | ResNet-18 CIFAR (FP32) | ... | ... | ... | ... |
  - **Labels** : `documentation`, `rÃ©sultats`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J3-13** | Documenter les hyperparamÃ¨tres
  - **Description** : CrÃ©er une fiche reproductibilitÃ© avec tous les paramÃ¨tres utilisÃ©s
  - **Labels** : `documentation`, `reproductibilitÃ©`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

- [ ] **J3-14** | PrÃ©parer le teacher pour distillation
  - **Description** :
    - VÃ©rifier que le checkpoint est bien sauvegardÃ©
    - Tester le chargement du modÃ¨le
    - S'assurer que le modÃ¨le peut gÃ©nÃ©rer des soft labels
  - **Labels** : `prÃ©paration`, `distillation`
  - **PrioritÃ©** : ğŸŸ¡ Moyenne

---

## âœ… CritÃ¨res d'acceptation J3

- [ ] ResNet-18 adaptÃ©e CIFAR implÃ©mentÃ©e
- [ ] **Accuracy â‰¥85%** sur CIFAR-10 test
- [ ] Mesures latence (moyenne + p95) documentÃ©es
- [ ] Tableau comparatif mis Ã  jour (ligne B2)
- [ ] Checkpoint teacher prÃªt pour J4

---

## ğŸ“ˆ Sorties attendues

| Livrable | Statut |
|----------|--------|
| ResNet-18 CIFAR entraÃ®nÃ©e | â¬œ |
| Accuracy â‰¥85% atteinte | â¬œ |
| Latence GPU (FP32) mesurÃ©e | â¬œ |
| Tableau comparatif (ligne B2) | â¬œ |
| Teacher prÃªt pour distillation | â¬œ |

---

## ğŸš¨ Points d'attention

- Si accuracy < 85% aprÃ¨s 200 epochs :
  - Augmenter les epochs (300)
  - Ajouter augmentations (Cutout, MixUp)
  - Ajuster LR schedule
- ResNet-18 standard (ImageNet) ne convient pas directement Ã  CIFAR (32Ã—32)
- Le teacher doit Ãªtre robuste car il guidera le student en J4

---

## ğŸ“š RÃ©fÃ©rences utiles

- Architecture ResNet-18 CIFAR : premiÃ¨re conv 3Ã—3, pas de maxpool
- HyperparamÃ¨tres classiques : LR=0.1, SGD momentum=0.9, WD=5e-4
- Accuracy attendue ResNet-18 CIFAR : ~93-95% (avec bonne config)

